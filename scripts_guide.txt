you have 2 scripts now added:
    1. scp_repo.sh that you call like "./scp_repo.sh {password}" 
where password is the password for the studios. call this from the 
root of the repo and it will send any differences in your local repo 
to the machines. this should only be needed when things changed
    2. run_remote.sh, also called like "./run_remote.sh {password}"
which kills all running exo process and starts new ones with fresh dbs

both of these use the file hosts.json which is a json list of strings
of the form user@ip where you need to put the studios with their username
and THUNDERBOLT ips (get these manually from the machines after all of
them and your laptop are hooked up via tb5 and have ips on the thunderbolt
bridge in settings>network). the order here doesn't matter EXCEPT for the
first entry which will be the master. so the script runs ./run.sh -c on the
first entry in that list and ./run.sh -rc on all the others


separately, there is now a nodes.json which is also a list of strings but this
time of the node ids of the machines (the uuid that gets generated in python
and printed when the process starts etc). here you do need them in the exact
order the machines are connected in via thunderbolt. this is used to prefer
spawning models across machines 1-2 and then 3-4 in that order if doable